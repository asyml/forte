{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Pipeline\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from termcolor import colored\n",
    "from forte.data.readers import ClassificationDatasetReader\n",
    "from fortex.huggingface import ZeroShotClassifier\n",
    "from forte.pipeline import Pipeline\n",
    "from fortex.nltk import NLTKSentenceSegmenter\n",
    "from ft.onto.base_ontology import Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Background\n",
    "This notebook tutorial is derived from [a classification example](https://github.com/asyml/forte/tree/master/examples/classification).\n",
    "Given a table-like csv file with data at some columns are input text and data at one column is label, we set up a text classification pipeline below. This example is also a good example of wrapping external library classes/methods into `PipelineComponent`.\n",
    "\n",
    "\n",
    "## Inference Workflow\n",
    "\n",
    "### Pipeline\n",
    "* [Pipeline setup](https://github.com/asyml/forte/blob/master/examples/classification/bank_customer_intent.py#L123)\n",
    "\n",
    "* The pipeline has one reader `ClassificationDatasetReader` and two processor\n",
    "`NLTKSentenceSegmenter` and `ZeroShotClassifier`. \n",
    "\n",
    "\n",
    "### Reader\n",
    "* [ClassificationDatasetReader](https://github.com/asyml/forte/blob/7dc6e6c7d62d9a4126bdfc5ca02d15be3ffd61ca/forte/data/readers/classification_reader.py#L26)\n",
    "    * `set_up()`: It checks whether the configuration is correct. For example, `skip_k_starting_lines` should be larger than 0 otherwise it doesn't make sense. It also converts different table data at the label column to a digit.\n",
    "    * `_collect()`: read rows from csv file and returns iterator that yields line id and line data.\n",
    "    * `_cache_key_function()`: use the line id as the cache key. \n",
    "    * `_parse_pack()`: parse data from iterator returned by `_collect` and load it in the datapack\n",
    "\n",
    "\n",
    "\n",
    "### Processor\n",
    "In this example, we want to classify data sentence by sentence so we wrapped `nltk.PunktSentenceTokenizer` in [NLTKSentenceSegmenter](https://github.com/asyml/forte-wrappers/blob/80cfe19926c0596edd13985581e8ca01a7be86ad/src/nltk/fortex/nltk/nltk_processors.py#L247) to segment sentences. \n",
    "\n",
    "* `_process()`: split data pack text into sentence spans.\n",
    "\n",
    "\n",
    "\n",
    "Then need a model to do classification. We wrap `transformers.pipeline` in \n",
    "[Huggingface ZeroShotClassifier](https://github.com/asyml/forte-wrappers/blob/main/src/huggingface/fortex/huggingface/zero_shot_classifier.py).\n",
    "\n",
    "* `_process()`: running classifier over data pack data and write the prediction results back to data pack.\n",
    "\n",
    "`ZeroShotClassifier` and `NLTKSentenceSegmenter` both inherit from `PackProcessor` as it processes one `DataPack` at a time. Suppose if we processes one `MultiPack` at a time, we need to inherit `MultiPackProcessor` instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_path = \"data_samples/amazon_review_polarity_csv/sample.csv\"\n",
    "pl = Pipeline()\n",
    "\n",
    "# initialize labels\n",
    "class_names = [\"negative\", \"positive\"]\n",
    "index2class = dict(enumerate(class_names))\n",
    "pl.set_reader(\n",
    "    ClassificationDatasetReader(), config={\"index2class\": index2class}\n",
    ")\n",
    "pl.add(NLTKSentenceSegmenter())\n",
    "pl.add(ZeroShotClassifier(), config={\"candidate_labels\": class_names})\n",
    "pl.initialize()\n",
    "\n",
    "\n",
    "for pack in pl.process_dataset(csv_path):\n",
    "    for sent in pack.get(Sentence):\n",
    "        if (\n",
    "            input(\"Type n for the next documentation and its prediction: \").lower()\n",
    "            == \"n\"\n",
    "        ):\n",
    "            sent_text = sent.text\n",
    "            print(colored(\"Sentence:\", \"red\"), sent_text, \"\\n\")\n",
    "            print(colored(\"Prediction:\", \"blue\"), sent.classification)\n",
    "        else:\n",
    "            print(\"Exit the program due to unrecognized input\")\n",
    "            sys.exit()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef24553d1198fce4a0be9f455df40aff4e6272106653c30479d64479a9d4460b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('forte_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
