{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Pipeline\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from termcolor import colored\n",
    "from forte.data.readers import ClassificationDatasetReader\n",
    "from fortex.huggingface import ZeroShotClassifier\n",
    "from forte.pipeline import Pipeline\n",
    "from fortex.nltk import NLTKSentenceSegmenter\n",
    "from ft.onto.base_ontology import Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Background\n",
    "This notebook tutorial is derived from [a classification example](https://github.com/asyml/forte/tree/master/examples/classification).\n",
    "Given a table-like csv file with data at some columns are input text and data at one column is label, we set up a text classification pipeline below. This example is also a good example of wrapping external library classes/methods into `PipelineComponent`.\n",
    "\n",
    "\n",
    "## Inference Workflow\n",
    "\n",
    "### Pipeline\n",
    "* [Pipeline setup](https://github.com/asyml/forte/blob/master/examples/classification/bank_customer_intent.py#L123)\n",
    "\n",
    "* The pipeline has one reader `ClassificationDatasetReader` and two processor\n",
    "`NLTKSentenceSegmenter` and `ZeroShotClassifier`. \n",
    "\n",
    "\n",
    "### Reader\n",
    "* [ClassificationDatasetReader](https://github.com/asyml/forte/blob/7dc6e6c7d62d9a4126bdfc5ca02d15be3ffd61ca/forte/data/readers/classification_reader.py#L26)\n",
    "    * `set_up()`: It checks whether the configuration is correct. For example, `skip_k_starting_lines` should be larger than 0 otherwise it doesn't make sense. It also converts different table data at the label column to a digit.\n",
    "    * `_collect()`: read rows from csv file and returns iterator that yields line id and line data.\n",
    "    * `_cache_key_function()`: use the line id as the cache key. \n",
    "    * `_parse_pack()`: parse data from iterator returned by `_collect` and load it in the datapack\n",
    "\n",
    "\n",
    "\n",
    "### Processor\n",
    "In this example, we want to classify data sentence by sentence so we wrapped `nltk.PunktSentenceTokenizer` in [NLTKSentenceSegmenter](https://github.com/asyml/forte-wrappers/blob/80cfe19926c0596edd13985581e8ca01a7be86ad/src/nltk/fortex/nltk/nltk_processors.py#L247) to segment sentences. \n",
    "\n",
    "* `_process()`: split data pack text into sentence spans.\n",
    "\n",
    "\n",
    "\n",
    "Then need a model to do classification. We wrap `transformers.pipeline` in \n",
    "[Huggingface ZeroShotClassifier](https://github.com/asyml/forte-wrappers/blob/main/src/huggingface/fortex/huggingface/zero_shot_classifier.py).\n",
    "\n",
    "* `_process()`: running classifier over data pack data and write the prediction results back to data pack.\n",
    "\n",
    "`ZeroShotClassifier` and `NLTKSentenceSegmenter` both inherit from `PackProcessor` as it processes one `DataPack` at a time. Suppose if we processes one `MultiPack` at a time, we need to inherit `MultiPackProcessor` instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Re-declared a new class named [ConstituentNode], which is probably used in import.\n",
      "[nltk_data] Downloading package punkt to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSentence:\u001b[0m One of the best game music soundtracks - for a game I didn't really play\n",
      "Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. \n",
      "\n",
      "\u001b[34mPrediction:\u001b[0m {'positive': 0.954, 'negative': 0.0054}\n",
      "\u001b[31mSentence:\u001b[0m There is an incredible mix of fun, epic, and emotional songs. \n",
      "\n",
      "\u001b[34mPrediction:\u001b[0m {'positive': 0.0115, 'negative': 0.0001}\n",
      "\u001b[31mSentence:\u001b[0m Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. \n",
      "\n",
      "\u001b[34mPrediction:\u001b[0m {'negative': 0.0002, 'positive': 0.0001}\n",
      "Exit the program due to unrecognized input\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murphy/anaconda3/envs/forte_org_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3532: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_path = \"../../data_samples/amazon_review_polarity_csv/sample.csv\"\n",
    "pl = Pipeline()\n",
    "\n",
    "# initialize labels\n",
    "class_names = [\"negative\", \"positive\"]\n",
    "index2class = dict(enumerate(class_names))\n",
    "pl.set_reader(\n",
    "    ClassificationDatasetReader(), config={\"index2class\": index2class}\n",
    ")\n",
    "pl.add(NLTKSentenceSegmenter())\n",
    "pl.add(ZeroShotClassifier(), config={\"candidate_labels\": class_names})\n",
    "pl.initialize()\n",
    "\n",
    "\n",
    "for pack in pl.process_dataset(csv_path):\n",
    "    for sent in pack.get(Sentence):\n",
    "        if (\n",
    "            input(\"Type n for the next documentation and its prediction: \").lower()\n",
    "            == \"n\"\n",
    "        ):\n",
    "            sent_text = sent.text\n",
    "            print(colored(\"Sentence:\", \"red\"), sent_text, \"\\n\")\n",
    "            print(colored(\"Prediction:\", \"blue\"), sent.classification)\n",
    "        else:\n",
    "            print(\"Exit the program due to unrecognized input\")\n",
    "            sys.exit()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef24553d1198fce4a0be9f455df40aff4e6272106653c30479d64479a9d4460b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('forte_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
