{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from termcolor import colored\n",
    "from forte.data.readers import ClassificationDatasetReader\n",
    "from fortex.huggingface import ZeroShotClassifier\n",
    "from forte.pipeline import Pipeline\n",
    "from fortex.nltk import NLTKSentenceSegmenter\n",
    "from ft.onto.base_ontology import Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "This notebook tutorial is derived from https://github.com/asyml/forte/tree/master/examples/classification\n",
    "Given a table-like csv file with data at some columns are input text and data at one column is label, we set up a text classification pipeline below. This example is also a good tutorial of wrapping external library classes/methods into `PipelineComponent`\n",
    "\n",
    "\n",
    "## Inference Workflow\n",
    "\n",
    "### Pipeline\n",
    "User can refer the code link here: https://github.com/asyml/forte/blob/master/examples/classification/bank_customer_intent.py#L123\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Reader\n",
    "For simplicity, user can refer the code link here: \n",
    "https://github.com/asyml/forte/blob/7dc6e6c7d62d9a4126bdfc5ca02d15be3ffd61ca/forte/data/readers/classification_reader.py#L26\n",
    "\n",
    "* set_up(): set up class variables, check configurations\n",
    "* initialize: intialize resources? \n",
    "* collect: read rows from csv table\n",
    "* cache_key_function: line id\n",
    "* _parse_pack: parse data from iterator and load it in datapack\n",
    "\n",
    "\n",
    "\n",
    "### Processor\n",
    "\n",
    "NLTKSentenceSegmenter\n",
    "\n",
    "https://github.com/asyml/forte-wrappers/blob/80cfe19926c0596edd13985581e8ca01a7be86ad/src/nltk/fortex/nltk/nltk_processors.py#L247\n",
    "\n",
    "\n",
    "\n",
    "Huggingface classifier\n",
    "https://github.com/asyml/forte-wrappers/blob/main/src/huggingface/fortex/huggingface/zero_shot_classifier.py\n",
    "\n",
    "\n",
    "\n",
    "RequestPackingProcessor\n",
    "\n",
    "A processor that implements the packing batch processor, using a\n",
    "    variation of the fixed size batcher\n",
    "    :class:`~forte.data.batchers.FixedSizeRequestDataPackBatcher`,\n",
    "    which will use `DataPack.get_data` function with the`context_type`\n",
    "    and `requests` parameters.\n",
    "\n",
    "class PackingBatchProcessor(BaseBatchProcessor[PackType], ABC):\n",
    "    \"\"\"\n",
    "    This class extends the BaseBatchProcessor class and provide additional\n",
    "    utilities to align and pack the extracted results back to the data pack.\n",
    "\n",
    "    To implement this processor, one need to implement:\n",
    "    1. The `predict` function that make predictions for each input data batch.\n",
    "    2. The `pack` function that add the prediction value back to the data pack.\n",
    "\n",
    "    Users that implement the processor only have to concern about a single\n",
    "    batch, the alignment between the data batch and the data pack will be\n",
    "    maintained by the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "csv_path = \"data_samples/amazon_review_polarity_csv/sample.csv\"\n",
    "pl = Pipeline()\n",
    "\n",
    "# initialize labels\n",
    "class_names = [\"negative\", \"positive\"]\n",
    "index2class = dict(enumerate(class_names))\n",
    "pl.set_reader(\n",
    "    ClassificationDatasetReader(), config={\"index2class\": index2class}\n",
    ")\n",
    "pl.add(NLTKSentenceSegmenter())\n",
    "pl.add(ZeroShotClassifier(), config={\"candidate_labels\": class_names})\n",
    "pl.initialize()\n",
    "\n",
    "\n",
    "for pack in pl.process_dataset(csv_path):\n",
    "    for sent in pack.get(Sentence):\n",
    "        if (\n",
    "            input(\"Type n for the next documentation and its prediction: \").lower()\n",
    "            == \"n\"\n",
    "        ):\n",
    "            sent_text = sent.text\n",
    "            print(colored(\"Sentence:\", \"red\"), sent_text, \"\\n\")\n",
    "            print(colored(\"Prediction:\", \"blue\"), sent.classification)\n",
    "        else:\n",
    "            print(\"Exit the program due to unrecognized input\")\n",
    "            sys.exit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
