{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1489859",
   "metadata": {},
   "source": [
    "# Zero-Shot Text Classification\n",
    "\n",
    "Text classification, also known as text tagging or text categorization, is the process of categorizing text into organized groups. Using Natural Language Processing (NLP), text classifiers can automatically analyze text and then assign a set of pre-defined tags or categories based on its content. For example, the emails received go through a text classification task of filtering spam vs. non-spam emails. Social media platforms use text classification to determine whether comments should be flagged as inappropriate.\n",
    "\n",
    "The goal of this tutorial is to:\n",
    "\n",
    " * Introduce you to text classification with Zero-Shot Learning\n",
    " * learn to write custom python functions to evaluate our model\n",
    " * Get your hands dirty with coding experiments to improve our model performance.\n",
    "\n",
    "Along the way, we will go through the Forte pipeline and learn how well it integrates with other third-party libraries like `HuggingFace` and `NLTK`.\n",
    "\n",
    "Before looking at this tutorial, we first need to appreciate the broad scope of this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371c5c4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In general, most machine learning-based modeling involves these three important steps :\n",
    "\n",
    " * Data gathering and processing\n",
    " * Modeling\n",
    " * Evaluation\n",
    "\n",
    "However, the gathered data is very low to train a deep neural network(`DNN`) model in some cases. In such cases, we generally use a pre-trained `DNN` model trained on some large dataset, and then we 'fine-tune' the model on our dataset. This kind of modeling is called transfer learning. And Zero-Shot text classification is an extreme example of transfer learning, where the model tries to classify without any fine-tuning on a single data. This kind of model uses the similarity between the input text and label name to decide the class based on the highest similarity score. So this method does not need any labeled data. Well-defined Label names are sufficient to achieve good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da765cf",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this tutorial, we will be using a subset of the publicly available amazon review sentiment [ARS](https://s3.amazonaws.com/fast-ai-nlp/amazon_review_polarity_csv.tgz) dataset. Let's do some exploration of our sample data. You can also use the complete dataset by downloading it from the link above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce1f40b",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "We will use the Pandas library to read the CSV file and visualize the input data. There are three columns in the input CSV file.\n",
    "\n",
    " * Labels with value 1 are considered Negative, and value 2 are considered Positive.\n",
    " * Title as a short title to the review.\n",
    " * Body is the complete description of the review.\n",
    " \n",
    "We can use either of them as our text input to build our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2c7958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the data :  (20, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Great Music</td>\n",
       "      <td>I generally hate it when singers attempt to sing '60's and '70's Motown that were not a part of the Organization during that e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Useful but Advanced Tech. for Java Developers is better.</td>\n",
       "      <td>Advanced Tech. for Java Developers contains in one chapter what this book drags out. But ATFJD also gives you good info on Bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Dont order from worldofbookusa!</td>\n",
       "      <td>It has been a month since I ordered this book from worldofbookusa and I still have not received it. I'm sure the book is great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>One year on and overheated and failed</td>\n",
       "      <td>Fine until a year later the mouse pointer stopping and starting on the screen. I noticed the hub was hot, unplugged and let it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Worst Logitech mouse ever. Save your $ for a nicer model</td>\n",
       "      <td>Save your money and buy a better Logitech mouse than this. They should be embarrassed at the LOW quality of this mouse. The ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                                     Title  \\\n",
       "6       2                                               Great Music   \n",
       "11      1  Useful but Advanced Tech. for Java Developers is better.   \n",
       "7       1                           Dont order from worldofbookusa!   \n",
       "0       1                     One year on and overheated and failed   \n",
       "10      1  Worst Logitech mouse ever. Save your $ for a nicer model   \n",
       "\n",
       "                                                                                                                     Body_Description  \n",
       "6   I generally hate it when singers attempt to sing '60's and '70's Motown that were not a part of the Organization during that e...  \n",
       "11  Advanced Tech. for Java Developers contains in one chapter what this book drags out. But ATFJD also gives you good info on Bea...  \n",
       "7   It has been a month since I ordered this book from worldofbookusa and I still have not received it. I'm sure the book is great...  \n",
       "0   Fine until a year later the mouse pointer stopping and starting on the screen. I noticed the hub was hot, unplugged and let it...  \n",
       "10  Save your money and buy a better Logitech mouse than this. They should be embarrassed at the LOW quality of this mouse. The ba...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# if you want to change your input file, you can change it below.\n",
    "csv_path = \"../../data_samples/amazon_review_polarity_csv/amazon_sample_20.csv\"\n",
    "# to use the full width of the notebook, lets set the columnwidth to 150\n",
    "pd.set_option('display.max_colwidth', 130)\n",
    "df=pd.read_csv(csv_path)\n",
    "print('size of the data : ',df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c1b5d",
   "metadata": {},
   "source": [
    "Let's also check the class balance of the data by using `groupby` and count functions in pandas. The sample data is unbalanced significantly, so even if our model predicts label '1' for any input, our accuracy will be 14/(14+6) = 70%. So the base accuracy of our model should be at least greater than 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811e0fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Title  Body_Description\n",
      "label                         \n",
      "1         14                14\n",
      "2          6                 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14f3dd261310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfc=df.groupby('label').count()\n",
    "print(dfc)\n",
    "dfc.plot(kind='bar').legend(loc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a34f71",
   "metadata": {},
   "source": [
    "Let's print two random samples from the Body_Description column. We can find that the text sample has multiple sentences. So we will split each text sample into individual sentences using `NLTKSentenceSegmenter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59598ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample A : \n",
      " Advanced Tech. for Java Developers contains in one chapter what this book drags out. But ATFJD also gives you good info on Beans, Servlets, JNI ... . If some one gives you a copy of Java RMI you will get something out of it, but buy the other one. I bought both (sigh). \n",
      "\n",
      "sample B : \n",
      " Got this movie as part of a box set. Best thing about the movie is that it is less than 90 minutes long.\n"
     ]
    }
   ],
   "source": [
    "print('sample A : \\n',df['Body_Description'][11],'\\n')\n",
    "print('sample B : \\n',df['Body_Description'][15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55b7e7",
   "metadata": {},
   "source": [
    "Forte pipeline will help us manage the flow of operations needed to make our predictions. \n",
    "\n",
    " * The first component in our pipeline will be the data reader, using [ClassificationDatasetReader](https://github.com/asyml/forte/blob/bd20b54203dd2083e3d401a55f44d6d7b690bed6/forte/data/readers/classification_reader.py).\n",
    " * The second component will be the sentence segmentation model from [NLTKSentenceSegmenter](https://github.com/asyml/forte-wrappers/blob/main/src/nltk/fortex/nltk/nltk_processors.py#:~:text=class%20NLTKSentenceSegmenter(PackProcessor))\n",
    " * The Third component will be our text classifier [ZeroShotClassifier](https://github.com/asyml/forte-wrappers/blob/7c2fd5d21fbc3cd4c66596c2182b8299e2ce6a86/src/huggingface/fortex/huggingface/zero_shot_classifier.py#:~:text=class%20ZeroShotClassifier(PackProcessor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2e6644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forte.pipeline import Pipeline\n",
    "from forte.data.readers import ClassificationDatasetReader\n",
    "from fortex.nltk import NLTKSentenceSegmenter\n",
    "from fortex.huggingface import ZeroShotClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a821b6a",
   "metadata": {},
   "source": [
    "Defining class names and converting them into a numerical representation. We have to keep in mind to select very meaningful class names for this kind of modeling. We will later see how the definition of class names changes the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3ff1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"negative\", \"positive\"]\n",
    "index2class = dict(enumerate(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d740a",
   "metadata": {},
   "source": [
    "`cuda_device`: Device ordinal for CPU/GPU supports. Setting\n",
    "              this to -1 will leverage CPU, a positive will run the model\n",
    "              on the associated CUDA device id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9b7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device=0 # -1 for cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8defd389",
   "metadata": {},
   "source": [
    "You can also select the name of the pre-trained model from [HuggingFace](https://huggingface.co/models?pipeline_tag=zero-shot-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f28c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"valhalla/distilbart-mnli-12-1\" # i.e, \"facebook/bart-large-mnli\", \"joeddav/bart-large-mnli-yahoo-answers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fadd701",
   "metadata": {},
   "source": [
    "Let's put everything into the Forte pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01ba12a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Re-declared a new class named [ConstituentNode], which is probably used in import.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/bhaskar.rao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "pl = Pipeline()\n",
    "pl.set_reader(ClassificationDatasetReader(), config={\"index2class\": index2class})\n",
    "pl.add(NLTKSentenceSegmenter())\n",
    "pl.add(ZeroShotClassifier(), config={\"candidate_labels\": class_names,\n",
    "                                     \"model_name\": model_name ,\n",
    "                                     \"cuda_device\":cuda_device})\n",
    "pl.initialize();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de32e2",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "We will predict a sentence from the description column using the above pipeline. We can see that the `NLTKSentenceSegmenter` has split the text in each input row into individual sentences. Then `ZeroShotClassifier` is making predictions for each sentence. The number beside the Label name is the confidence score for the prediction is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c48bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ft.onto.base_ontology import Sentence\n",
    "from ft.onto.base_ontology import Document\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16106e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mOriginal Text : \u001b[0m \n",
      " One year on and overheated and failed\n",
      "Fine until a year later the mouse pointer stopping and starting on the screen. I noticed the hub was hot, unplugged and let it cool and start again. The problem then started more frequently and the unit became very hot. Had to toss it in the end. Won't buy Belkin again. \n",
      "\n",
      "\u001b[31mSentence:\u001b[0m One year on and overheated and failed\n",
      "Fine until a year later the mouse pointer stopping and starting on the screen.\n",
      "\u001b[34mPrediction:\u001b[0m {'negative': 0.8738, 'positive': 0.0285} \n",
      "\n",
      "\u001b[31mSentence:\u001b[0m I noticed the hub was hot, unplugged and let it cool and start again.\n",
      "\u001b[34mPrediction:\u001b[0m {'positive': 0.0924, 'negative': 0.0363} \n",
      "\n",
      "\u001b[31mSentence:\u001b[0m The problem then started more frequently and the unit became very hot.\n",
      "\u001b[34mPrediction:\u001b[0m {'negative': 0.2644, 'positive': 0.0011} \n",
      "\n",
      "\u001b[31mSentence:\u001b[0m Had to toss it in the end.\n",
      "\u001b[34mPrediction:\u001b[0m {'negative': 0.9785, 'positive': 0.0075} \n",
      "\n",
      "\u001b[31mSentence:\u001b[0m Won't buy Belkin again.\n",
      "\u001b[34mPrediction:\u001b[0m {'negative': 0.9985, 'positive': 0.0837} \n",
      "\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for pack in pl.process_dataset(csv_path):\n",
    "    print(colored('Original Text : ',\"magenta\"),'\\n',pack.text,'\\n')\n",
    "    for sent in pack.get(Sentence):\n",
    "        sent_text = sent.text\n",
    "        print(colored(\"Sentence:\", \"red\"), sent_text)\n",
    "        print(colored(\"Prediction:\", \"blue\"), sent.classification, \"\\n\")\n",
    "    print('-----------------------------------------------------------')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7cfd2",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We can predict at sentence level now. Moreover, from the above example, it seems our model is doing very well. However, we need to evaluate our model with some metrics like accuracy to assess the quality in a quantifiable manner. Before that, we need to aggregate our sentence-level prediction to text level. Let's write an aggregate function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71888bc1",
   "metadata": {},
   "source": [
    "### Aggregate\n",
    "\n",
    "In order to aggregate our sentence predictions, we can average the confidence scores of each sentence in a text input. So let's define a function that will take the `pack` object and return the average confidence score of sentences in the `pack` text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd68036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_class_score(pack):\n",
    "    ''' aggregates class scores\n",
    "    input: pack object\n",
    "    output: returns average class score of sentences in the pack.text\n",
    "    '''\n",
    "    prediction_list=[] \n",
    "    avg_score={}\n",
    "    count_sentences=0\n",
    "    for sent in pack.get(Sentence):\n",
    "        for i in sent.classification.items():\n",
    "            try:\n",
    "                avg_score[i[0]]=avg_score[i[0]]+i[1]\n",
    "            except:\n",
    "                avg_score[i[0]]=i[1]\n",
    "        count_sentences+=1\n",
    "        \n",
    "    for i in avg_score.keys():\n",
    "        avg_score[i]=avg_score[i]/count_sentences\n",
    "        \n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210684f6",
   "metadata": {},
   "source": [
    "Let's write a small script to check our text prediction vs. ground truth and also save our results for evaluating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "762c3cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mOriginal Text : \u001b[0m \n",
      " One year on and overheated and failed\n",
      "Fine until a year later the mouse pointer stopping and starting on the screen. I noticed the hub was hot, unplugged and let it cool and start again. The problem then started more frequently and the unit became very hot. Had to toss it in the end. Won't buy Belkin again. \n",
      "\n",
      "\u001b[32mground_truth : \u001b[0m negative \u001b[34m     predicted_class : \u001b[0m negative \u001b[31m confidence score : \u001b[0m 0.6303 \n",
      "\n",
      "\u001b[35mOriginal Text : \u001b[0m \n",
      " Dont order from worldofbookusa!\n",
      "It has been a month since I ordered this book from worldofbookusa and I still have not received it. I'm sure the book is great but the supplier is not. \n",
      "\n",
      "\u001b[32mground_truth : \u001b[0m negative \u001b[34m     predicted_class : \u001b[0m negative \u001b[31m confidence score : \u001b[0m 0.6373333333333333 \n",
      "\n",
      "\u001b[35mOriginal Text : \u001b[0m \n",
      " Kung Fu Vampires\n",
      "Got this movie as part of a box set. Best thing about the movie is that it is less than 90 minutes long. \n",
      "\n",
      "\u001b[32mground_truth : \u001b[0m negative \u001b[34m     predicted_class : \u001b[0m positive \u001b[31m confidence score : \u001b[0m 0.5896 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true=[]\n",
    "y_pred=[]\n",
    "for c,pack in enumerate(pl.process_dataset(csv_path)):\n",
    "    yt=next(pack.get(Document)).document_class[0]\n",
    "    avg_score=aggregate_class_score(pack)\n",
    "    yp=pd.DataFrame.from_dict(avg_score,orient ='index')[0].idxmax()\n",
    "    ys=avg_score[yp] \n",
    "    y_true.append(yt)\n",
    "    y_pred.append(yp)\n",
    "    \n",
    "    if c%8==0:\n",
    "        print(colored('Original Text : ',\"magenta\"),'\\n',pack.text,'\\n')\n",
    "        #print(pack.text,'\\n')\n",
    "        print(colored('ground_truth : ','green'),\n",
    "              yt,colored('     predicted_class : ','blue'),\n",
    "              yp,colored(' confidence score : ','red'),ys,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb56fb",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "We will use the [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy#sklearn.metrics.accuracy_score) library to evaluate accuracy. In the previous block, we stored the ground truth and prediction in two lists. `accuracy_score` from `sklearn` will take these as input and return the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de79a47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d24abc",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "Here we will explore ways to improve the accuracy of our model on a given dataset. As we know, the Zero_Shot model makes predictions based on the similarity between the input sentence and the class names. So we can experiment with different class names similar to the original class names and find out which class names work best for our dataset. So let's write a function that combines all the above necessary steps to conduct this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdbd0f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(csv_path,Label_1='negative',Label_2='positive',model_name='valhalla/distilbart-mnli-12-1',cuda_device=0):\n",
    "    '''This function unifies the initialization, prediction and accuracy evaluation.\n",
    "    input : csv_path and class names\n",
    "    output : accuracy'''\n",
    "    class_names = [Label_1, Label_2]\n",
    "    index2class={0:Label_1,1: Label_2}\n",
    "    \n",
    "    pl = Pipeline()\n",
    "    pl.set_reader(ClassificationDatasetReader(), config={\"index2class\": index2class})\n",
    "    pl.add(NLTKSentenceSegmenter())\n",
    "    pl.add(ZeroShotClassifier(), config={\"candidate_labels\": class_names,\n",
    "                                         \"model_name\": model_name ,\n",
    "                                         \"cuda_device\":cuda_device})\n",
    "    pl.initialize();\n",
    "\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "    for c,pack in enumerate(pl.process_dataset(csv_path)):\n",
    "        yt=next(pack.get(Document)).document_class[0]\n",
    "        avg_score=aggregate_class_score(pack)\n",
    "        yp=pd.DataFrame.from_dict(avg_score,orient ='index')[0].idxmax()\n",
    "        ys=avg_score[yp] \n",
    "        y_true.append(yt)\n",
    "        y_pred.append(yp)\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4f60830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Re-declared a new class named [ConstituentNode], which is probably used in import.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/bhaskar.rao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(csv_path,Label_1='unsatisfied',Label_2='satisfied',model_name='valhalla/distilbart-mnli-12-1',GPU=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e439712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Re-declared a new class named [ConstituentNode], which is probably used in import.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/bhaskar.rao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(csv_path,Label_1='unsatisfied',Label_2='satisfied',model_name='facebook/bart-large-mnli',GPU=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d727d9",
   "metadata": {},
   "source": [
    "Accuracy of 95% on unseen data is an exceptional performance from the Hugging-Face model. Zero-Shot learning is a powerful tool for low volume of label data. With an intelligent selection of class names, we can improve further. We can see that class names ('unsatisfied', 'satisfied') improved our accuracy by 5% compared to class names ('negative', 'positive'). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4757785",
   "metadata": {},
   "source": [
    "## HomeWork\n",
    "Your task is to define a list of similar class names grouped into tuples. Keep the order of the class names to be similar too. i.e., first the negative word, then the positive word. Add at least five extra pairs of class names to the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_list=[('negative','positive'),\n",
    "                ('unsatisfied','satisfied')\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae62864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name=[]\n",
    "accuracy_list=[]\n",
    "for i in class_name_list:\n",
    "    class_name.append(i[0]+'_'+i[1])\n",
    "    accuracy_list.append(accuracy(csv_path,Label_1=i[0],Label_2=i[1]))\n",
    "da=pd.DataFrame()\n",
    "da['class_name']=class_name\n",
    "da['accuracy']=accuracy_list\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c053762",
   "metadata": {},
   "source": [
    "You can also try different pretrained models from [HuggingFace](https://huggingface.co/models?pipeline_tag=zero-shot-classification) and find out which models perform better than others on your dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forte_dev",
   "language": "python",
   "name": "forte_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
