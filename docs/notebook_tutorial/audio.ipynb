{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd81569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r \"../../examples/audio/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} -c conda-forge librosa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422a5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import argmax\n",
    "import sounddevice\n",
    "import torch\n",
    "import pyannote.audio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "from forte.common.configuration import Config\n",
    "from forte.common.resources import Resources\n",
    "from forte.common.exception import ProcessFlowException\n",
    "from forte.data.data_pack import DataPack\n",
    "from forte.data.readers import AudioReader\n",
    "from forte.pipeline import Pipeline\n",
    "from forte.processors.base.pack_processor import PackProcessor\n",
    "\n",
    "from forte.data.ontology.top import Link\n",
    "from ft.onto.base_ontology import AudioUtterance, Utterance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0283e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeakerSegmentationProcessor(PackProcessor):\n",
    "    \"\"\"\n",
    "    An audio processor for speaker segmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    def initialize(self, resources: Resources, configs: Config):\n",
    "        super().initialize(resources, configs)\n",
    "        self._model = pyannote.audio.Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-segmentation\"\n",
    "        )\n",
    "\n",
    "    def _process(self, input_pack: DataPack):\n",
    "        output = self._model(input_pack.pack_name)\n",
    "        for turn, _, speaker in output.itertracks(yield_label=True):\n",
    "            audio_utter: AudioUtterance = AudioUtterance(\n",
    "                pack=input_pack,\n",
    "                begin=int(turn.start * input_pack.sample_rate),\n",
    "                end=int(turn.end * input_pack.sample_rate)\n",
    "            )\n",
    "            audio_utter.speaker = speaker\n",
    "\n",
    "\n",
    "class AudioUtteranceASRProcessor(PackProcessor):\n",
    "    \"\"\"\n",
    "    An audio processor for automatic speech recognition.\n",
    "    \"\"\"\n",
    "\n",
    "    def initialize(self, resources: Resources, configs: Config):\n",
    "        super().initialize(resources, configs)\n",
    "\n",
    "        # Initialize tokenizer and model\n",
    "        pretrained_model: str = \"facebook/wav2vec2-base-960h\"\n",
    "        self._tokenizer = Wav2Vec2Processor.from_pretrained(pretrained_model)\n",
    "        self._model = Wav2Vec2ForCTC.from_pretrained(pretrained_model)\n",
    "\n",
    "    def _process(self, input_pack: DataPack):\n",
    "        required_sample_rate: int = 16000\n",
    "        if input_pack.sample_rate != required_sample_rate:\n",
    "            raise ProcessFlowException(\n",
    "                f\"A sample rate of {required_sample_rate} Hz is requied by the\"\n",
    "                \" pretrained model.\"\n",
    "            )\n",
    "\n",
    "        for audio_utter in input_pack.get(AudioUtterance):\n",
    "\n",
    "            # tokenize\n",
    "            input_values = self._tokenizer(\n",
    "                audio_utter.audio, return_tensors=\"pt\", padding=\"longest\"\n",
    "            ).input_values  # Batch size 1\n",
    "\n",
    "            # take argmax and decode\n",
    "            transcription = self._tokenizer.batch_decode(\n",
    "                argmax(self._model(input_values).logits, dim=-1)\n",
    "            )\n",
    "\n",
    "            if not transcription[0]:\n",
    "                continue\n",
    "\n",
    "            input_pack.set_text(text=input_pack.text + transcription[0])\n",
    "\n",
    "            # Create annotations on audio and text utterance\n",
    "            text_utter: Utterance = Utterance(\n",
    "                pack=input_pack,\n",
    "                begin=len(input_pack.text) - len(transcription[0]),\n",
    "                end=len(input_pack.text)\n",
    "            )\n",
    "            text_utter.speaker = audio_utter.speaker\n",
    "            Link(pack=input_pack, parent=audio_utter, child=text_utter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121ca177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/l/users/bhaskar.rao/work/projects/forte/docs/notebook_tutorial'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209314db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_path='../../audio'\n",
    "audio_path='/l/users/bhaskar.rao/work/projects/forte/examples/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd90169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Re-declared a new class named [ConstituentNode], which is probably used in import.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<forte.pipeline.Pipeline at 0x14b55b64beb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and config the Pipeline\n",
    "pipeline = Pipeline[DataPack]()\n",
    "pipeline.set_reader(AudioReader(), config={\"file_ext\": \".wav\"})\n",
    "pipeline.add(SpeakerSegmentationProcessor())\n",
    "pipeline.add(AudioUtteranceASRProcessor())\n",
    "pipeline.initialize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc79d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "WARNING:root:Need to be cautious when changing the text of a data pack, existing entries may get affected. \n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "WARNING:root:Need to be cautious when changing the text of a data pack, existing entries may get affected. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKER_00: IMG CUFVERADGE CONTINUES NOW WITH OUR THER POLITICAL REPORTE MICHAEL DOUBT N\n",
      "\n",
      "SPEAKER_01: HE JOINS US LIFE FROM THE ALLERT CENTER WITH WHAT VOTERS THINK OF TO NIGHT'S DEBATE MICHAEL\n",
      "\n",
      "SPEAKER_02: EL WITH MAINLY REHASHED ARGUMENTS HERE ALMOST EVERY ON THE PANEL FELT THEY COULD HAVE USED A LITTLE LESS POLITICS AS USUAL BUT ON WHO WON THE DEBATE WHILE OUR PANEL WAS SPLIT ON PRETTY MUCH PARTY LINES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pack in pipeline.process_dataset(audio_path):\n",
    "    for asr_link in pack.get(Link):\n",
    "        audio_utter = asr_link.get_parent()\n",
    "        text_utter = asr_link.get_child()\n",
    "        print(f\"{text_utter.speaker}: {text_utter.text}\")\n",
    "        print()\n",
    "        #sounddevice.play(audio_utter.audio, pack.sample_rate)\n",
    "        sounddevice.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91e412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forte_dev",
   "language": "python",
   "name": "forte_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
